# ğŸ“ˆ Linear Regression â€” From Scratch (Gradient Descent Implementation)

This folder contains a complete implementation of **Linear Regression from scratch** using only **NumPy**.  
No `sklearn.LinearRegression` is used â€” the algorithm is implemented manually using **Gradient Descent**.

---

## ğŸ¯ Objective

Linear Regression aims to find the **best-fitting line** that predicts a continuous target variable `y` from an input feature `x`,  
by minimizing the difference between **predicted** and **actual** values.

---

## ğŸ§  Theoretical Overview

## ğŸ”¹ Hypothesis Function

For a single feature:

> **Å· = w Â· x + b**

For multiple features:

> **Å· = X Â· Î¸ + b**


Where

| Symbol | Meaning |
|:-------|:---------|
| `X` | Input features matrix of shape (m, n) |
| `Î¸` | Weight vector (parameters) of shape (n, 1) |
| `b` | Bias term (scalar) |
| `m` | Number of training examples |
| `n` | Number of features |

---

### ğŸ”¹ Cost Function â€” Mean Squared Error (MSE)

The cost function measures how well the model fits the data:

> **J(Î¸, b) = (1 / 2m) Î£ (Å·â½â±â¾ âˆ’ yâ½â±â¾)Â²**


Our goal is to minimize **J(Î¸, b)**.

---

### ğŸ”¹ Gradient Descent Update Rules

To minimize the cost function, parameters are updated iteratively as:

> **Î¸ := Î¸ âˆ’ Î± Ã— (1/m) Ã— Xáµ€ (Å· âˆ’ y)**  
> **b := b âˆ’ Î± Ã— (1/m) Ã— Î£ (Å·â½â±â¾ âˆ’ yâ½â±â¾)**


Where:

| Symbol | Meaning |
|:-------|:---------|
| `Î±` | Learning rate (controls the step size of each update) |
| `Å·` | Model predictions = XÎ¸ + b |

---

## âš™ï¸ Implementation Details

### ğŸ”¸ `Linear_Regression.py`

Defines the `LinearRegression` class:

**Attributes**
- `learning_rate` â†’ step size for gradient updates  
- `n_iterations` â†’ number of training iterations  
- `parameters` â†’ model weights  
- `bias` â†’ intercept term  

**Methods**
- `fit(X, y)` â†’ trains the model using gradient descent  
- `predict(X)` â†’ computes predictions for input data  

---

### ğŸ”¸ `Linear_Regression_test.py`

Demonstrates how to use the model:
1. Generates a random regression dataset using `sklearn.datasets.make_regression`
2. Splits data into training and testing sets
3. Trains the model and evaluates it using Mean Squared Error
4. Visualizes predictions using Matplotlib

---

## ğŸ“Š Visualization

After training, the code plots:
- ğŸŸ¦ Actual data points  
- âš« Predicted regression line  

Run the test file to visualize:
```bash
python Linear_Regression_test.py
Example output:
A line fitting the data points showing the learned relationship.
```

ğŸ” Example Parameters
Parameter	Example Value	Description
learning_rate	0.01	Controls convergence speed
n_iterations	1000	Number of gradient descent steps
Î¸	[wâ‚, wâ‚‚, â€¦, wâ‚™]	Feature weights
b	scalar	Bias/intercept term

ğŸ§¾ References

Andrew Ng â€” Machine Learning Course (Coursera)

Scikit-learn documentation: LinearRegression

â€œHands-On Machine Learning with Scikit-Learn, Keras & TensorFlowâ€ by AurÃ©lien GÃ©ron

Additional explanations adapted from Wikipedia - Linear Regression

Author: Mohamed Elberry

ğŸ’¡ Passionate about understanding ML from first principles



